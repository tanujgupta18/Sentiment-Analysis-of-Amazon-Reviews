{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad2fb19",
   "metadata": {},
   "source": [
    "###### In this notebook we will be doing some sentimental analysis in python using      two different techniques:\n",
    "\n",
    "##  1.VADER(Valence Aware Dictionary and sEntiment Reasoner) - Bag of words approach\n",
    "##  2.Roberta Pretrained Model from ü§ó\n",
    "##  3.Huggingface Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff2ea2",
   "metadata": {},
   "source": [
    "# Step 1 :Read in Data and NLTK Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import nltk\n",
    "nltk.data.path.append(\"C:/nltk_data\")\n",
    "nltk.download('averaged_perceptron_tagger', download_dir=\"C:/nltk_data\")\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ad506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv('amazon.csv')\n",
    "print(df.shape)\n",
    "df = df.head(500)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f43ee",
   "metadata": {},
   "source": [
    "## Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df['overall'].value_counts().sort_index() \\\n",
    "    .plot(kind='bar',\n",
    "          title='Count of Reviews by Stars',\n",
    "          figsize=(10, 5))\n",
    "ax.set_xlabel('Review Stars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92348e7c",
   "metadata": {},
   "source": [
    "## Basic NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00be53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = df['reviewText'][50]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "word_tokenizer = TreebankWordTokenizer()\n",
    "word_tokens = word_tokenizer.tokenize(example)\n",
    "print(word_tokens[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7913d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tagged = nltk.pos_tag(word_tokens)\n",
    "print(tagged[:10])  # View first 10 tagged tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d83a24",
   "metadata": {},
   "source": [
    "# Step 2. VADER Seniment Scoring\n",
    "### We will use NLTK's SentimentIntensityAnalyzer to get the neg/neu/pos scores of the text.\n",
    "\n",
    "#### This uses a \"bag of words\" approach:\n",
    "####    1.Stop words are removed\n",
    "####    2.each word is scored and combined to a total score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc7d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('I am so happy!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c19cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('This is the worst thing ever.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd592d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text = str(row['reviewText'])\n",
    "    res[i] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd60f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.merge(df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have sentiment score and metadata\n",
    "vaders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326fdb3",
   "metadata": {},
   "source": [
    "# Plot VADER results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db09a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=vaders, x='overall', y='compound')\n",
    "ax.set_title('Compound Score by Amazon Star Rating')\n",
    "plt.xlabel('Amazon Star Rating')\n",
    "plt.ylabel('Compound Sentiment Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "sns.barplot(data=vaders, x='overall', y='pos', ax=axs[0])\n",
    "sns.barplot(data=vaders, x='overall', y='neu', ax=axs[1])\n",
    "sns.barplot(data=vaders, x='overall', y='neg', ax=axs[2])\n",
    "\n",
    "axs[0].set_title('Positive Score by Rating')\n",
    "axs[1].set_title('Neutral Score by Rating')\n",
    "axs[2].set_title('Negative Score by Rating')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42351a85",
   "metadata": {},
   "source": [
    "# Step 3. Roberta Pretrained Model\n",
    "### Use a model trained of a large corpus of data.\n",
    "### Transformer model accounts for the words but also the context related to other words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65075df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd788af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e266fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER results on example\n",
    "example = df['reviewText'][50]\n",
    "print(example)\n",
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for Roberta Model\n",
    "encoded_text = tokenizer(example, return_tensors='pt')\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'roberta_neg' : scores[0],\n",
    "    'roberta_neu' : scores[1],\n",
    "    'roberta_pos' : scores[2]\n",
    "}\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdab0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg' : scores[0],\n",
    "        'roberta_neu' : scores[1],\n",
    "        'roberta_pos' : scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87070f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        text = str(row['reviewText'])  # fixed column name\n",
    "        myid = i  # using row index as ID\n",
    "\n",
    "        # VADER\n",
    "        vader_result = sia.polarity_scores(text)\n",
    "        vader_result_rename = {f\"vader_{k}\": v for k, v in vader_result.items()}\n",
    "\n",
    "        # RoBERTa\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "\n",
    "        # Merge both\n",
    "        both = {**vader_result_rename, **roberta_result}\n",
    "        res[myid] = both\n",
    "\n",
    "    except RuntimeError:\n",
    "        print(f'‚ö†Ô∏è Skipped long or problematic review at index {i}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(res).T\n",
    "\n",
    "# Combine with df using the index\n",
    "final_df = pd.concat([df, results_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68a0fb1",
   "metadata": {},
   "source": [
    "# Compare Scores between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6dba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf99bfc9",
   "metadata": {},
   "source": [
    "# Step 3. Combine and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=final_df,\n",
    "             vars=['vader_neg', 'vader_neu', 'vader_pos',\n",
    "                  'roberta_neg', 'roberta_neu', 'roberta_pos'],\n",
    "            hue='overall',\n",
    "            palette='tab10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fa870",
   "metadata": {},
   "source": [
    "# Step 4: Review Examples:\n",
    "##      Positive 1-Star and Negative 5-Star Reviews\n",
    "###      Lets look at some examples where the model scoring and review score differ the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f97d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most positive 1-star review (according to RoBERTa)\n",
    "final_df.query('overall == 1') \\\n",
    "    .sort_values('roberta_pos', ascending=False)[['reviewText']].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d036bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most positive 1-star review (according to VADER)\n",
    "final_df.query('overall == 1') \\\n",
    "    .sort_values('vader_pos', ascending=False)[['reviewText']].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce0e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nevative sentiment 5-Star view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most negative sentiment 5-star review (RoBERTa)\n",
    "final_df.query('overall == 5') \\\n",
    "    .sort_values('roberta_neg', ascending=False)['reviewText'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf237c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most negative sentiment 5-star review (VADER)\n",
    "final_df.query('overall == 5') \\\n",
    "    .sort_values('vader_neg', ascending=False)['reviewText'].values[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9118ef",
   "metadata": {},
   "source": [
    "#  Extra: The Transformers Pipeline\n",
    "##        Quick & easy way to run sentiment predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd81abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sent_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pipeline(\"I love sentiment analysis!\")\n",
    "# ‚ûú [{'label': 'POSITIVE', 'score': 0.999...}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pipeline(\"booo\")\n",
    "# ‚ûú [{'label': 'NEGATIVE', 'score': 0.998...}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38a0eaf",
   "metadata": {},
   "source": [
    "# The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852aafce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
